{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMl5wQ/T/u/uCWiM4izsasB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 변형(TRANSFORM)\n","##### 데이터가 항상 머신러닝 알고리즘 학습에 필요한 최종 처리가 된 형태로 제공되지는 않는다. 변형을 해서 데이터를 조작하고 학습에 적합하게 한다.\n","##### 모든 TorchVision 데이터셋들은 변형 로직을 갖고, 호출 가능한 객체를 받는 매개변수 두개(특징을 변경하기 위한 transform, 정답을 변경하기 위한 target_transform)를 갖는다.\n","##### FashionMNIST 특징은 PIL Image 형식이며, 정답은 정수이다. 학습을 하기 위해 정규화된 텐서 형태의 특징과 원-핫으로 인코딩된 텐서 형태의 정답이 필요하다. 이를 위해 ToTensor와 Lambda를 사용한다."],"metadata":{"id":"nxzW56pLVXIV"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fv1y2kcpSADF","executionInfo":{"status":"ok","timestamp":1702457343344,"user_tz":-540,"elapsed":10947,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"7229c566-1b19-4d35-da62-10711fa19d73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 16674570.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 266684.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 4981002.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 14030069.52it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import torch\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda\n","\n","ds = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n","    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",")"]},{"cell_type":"markdown","source":["## ToTensor()\n","##### ToTensor는 PIL Image나 NumPy ndarray를 FloatTensor로 변환하고, 이미지의 픽셀의 크기 값을 [0., 1.] 범위로 비례하여 조정한다."],"metadata":{"id":"bETLjOXNXYJP"}},{"cell_type":"markdown","source":["## Lambda 변형 (Transform)\n","##### Lambda 변형은 사용자 정의 람다 함수를 적용한다.\n","##### 여기서는 정수를 원-핫으로 부호화된 텐서로 바꾸는 함수를 정의한다. 이 함수는 먼저 크게 10짜리 영 텐서를 만들고, scatter_를 호출하여 주어진 정답 y에 해당하는 인덱스에 value=1을 할당한다."],"metadata":{"id":"piKHwfoyXr7A"}},{"cell_type":"code","source":["target_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"],"metadata":{"id":"v-T9sqxNSDeg","executionInfo":{"status":"ok","timestamp":1702457555319,"user_tz":-540,"elapsed":4,"user":{"displayName":"천준석","userId":"06369588489203998973"}}},"execution_count":2,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOhG+iBcGdU3FDV/krcC3AU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 신경망 모델 구성하기\n","##### 신경망은 데이터에 대한 연산을 수행하는 계층/모듈로 구성되어 있다.\n","##### torch.nn 네임스페이스는 신경망을 구성하는데 필요한 모든 구성 요소를 제공한다.\n","##### PyTorch의 모든 모듈은 nn.Module의 하위 클래스이다. 신경망은 다른 모듈로 구성된 모듈이다. 이러한 중첩된 구조는 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있다."],"metadata":{"id":"FKYW7Y7FdZZT"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"D0VY2LVsc0eh","executionInfo":{"status":"ok","timestamp":1702459356016,"user_tz":-540,"elapsed":6638,"user":{"displayName":"천준석","userId":"06369588489203998973"}}},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","source":["## 학습을 위한 장치 얻기\n","##### 가능한 경우 GPU 또는 MPS와 같은 하드웨어 가속기에서 모델을 학습하려고 한다.\n","##### torch.cuda 또는 torch.backends.mps가 사용 가능한지 확인해보고, 그렇지 않으면 CPU를 계속 사용한다."],"metadata":{"id":"vl1GmEcqfTl6"}},{"cell_type":"code","source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERioFcdke_hb","executionInfo":{"status":"ok","timestamp":1702459590320,"user_tz":-540,"elapsed":9,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"79ec941d-06ff-488f-bda3-022315cad4a5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["## 클래스 정의하기\n","##### 신경망 모델을 nn.Module의 하위클래스로 정의하고, _ _init_ _에서 신경망 계층들을 초기화한다. nn.Module을 상속받은 모든 클래스는 forward 메소드에 입력 데이터에 대한 연산들을 구현한다."],"metadata":{"id":"-blvZv41f8-V"}},{"cell_type":"code","source":["class NeuralNetwork(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.flatten = nn.Flatten()\n","    self.linear_relu_stack = nn.Sequential(\n","        nn.Linear(28*28, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 10)\n","    )\n","  def forward(self, x):\n","    x = self.flatten(x)\n","    logits = self.linear_relu_stack(x)\n","    return logits"],"metadata":{"id":"KemRMrIxf8MJ","executionInfo":{"status":"ok","timestamp":1702460543087,"user_tz":-540,"elapsed":4,"user":{"displayName":"천준석","userId":"06369588489203998973"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["##### NeuralNetwork의 인스턴스를 생성하고 device 이동 후 구조 출력\n"],"metadata":{"id":"wu3BXT4ph4zR"}},{"cell_type":"code","source":["model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81bDn6xuh3s_","executionInfo":{"status":"ok","timestamp":1702460543374,"user_tz":-540,"elapsed":3,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"6b5d7613-9ab7-4cc2-a6cb-5a17a1afa8a6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["##### 모델을 사용하기 위해 입력 데이터를 전달한다. 이는 일부 백그라운드 연산들과 함께 모델의 forward를 실행한다. (model.forward()를 직접 호출하지 마라!)\n","##### 모델에 입력을 전달하여 호출하면 2차원 텐서를 반환한다. 2차원 텐서의 dim=0은 각 분류에 대한 원시 예측값 10개가, dim=1에는 각 출력의 개별 값들이 해당한다.\n","##### 원시 예측값을 nn.Softmax 모듈의 인스턴스에 통과시켜 예측 확률을 얻는다."],"metadata":{"id":"PPB6svQ4ii-D"}},{"cell_type":"code","source":["X = torch.rand(1, 28, 28, device=device)\n","logits = model(X)\n","pred_probab = nn.Softmax(dim=1)(logits)\n","y_pred = pred_probab.argmax(1)\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YxtVzXoBidp1","executionInfo":{"status":"ok","timestamp":1702460544186,"user_tz":-540,"elapsed":5,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"ad784353-02c4-4b7e-8d57-b7a6d5a54f2f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1])\n"]}]},{"cell_type":"markdown","source":["## 모델 계층(Layer)\n","##### FashionMNIST 모델의 계층들을 살펴보자. 임시로 28 X 28 크기의 이미지 3개로 구성된 미니배치를 가져와, 신경망을 통과할 때 어떤 일이 발생하는지 볼 것이다."],"metadata":{"id":"VGFyIrhyjsbl"}},{"cell_type":"code","source":["input_image = torch.rand(3,28,28)\n","print(input_image.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZgBYoHqdjafA","executionInfo":{"status":"ok","timestamp":1702460948396,"user_tz":-540,"elapsed":11,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"e64b223e-e59a-4040-dfdc-8557a9767b69"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 28, 28])\n"]}]},{"cell_type":"markdown","source":["### nn.Flatten\n","##### nn.Flatten : 계층을 초기화하여 각 28 x 28의 2D 이미지를 784 픽셀 값을 갖는 연속된 배열로 반환한다."],"metadata":{"id":"3CE9IVDulImt"}},{"cell_type":"code","source":["flatten = nn.Flatten()\n","flat_image = flatten(input_image)\n","print(flat_image.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCo0pbTilHrN","executionInfo":{"status":"ok","timestamp":1702461021902,"user_tz":-540,"elapsed":10,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"ba43da85-cd04-48fe-db2d-5a105bb76865"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 784])\n"]}]},{"cell_type":"markdown","source":["### nn.Linear\n","##### 선형 계층 : 저장된 가중치와 편향을 사용하여 입력에 선형 변환을 적용하는 모듈이다."],"metadata":{"id":"w3B_v4MdladM"}},{"cell_type":"code","source":["layer1 = nn.Linear(in_features=28*28, out_features=20)\n","hidden1 = layer1(flat_image)\n","print(hidden1.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnouOgNzlZzI","executionInfo":{"status":"ok","timestamp":1702461170115,"user_tz":-540,"elapsed":10,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"df69cba0-c5ea-420e-ce46-de0c791aaaa3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 20])\n"]}]},{"cell_type":"markdown","source":["### nn.ReLU\n","##### 비선형 활성화는 모델의 입력과 출력 사이에 복잡한 관계를 만든다. 비선형 활성화는 선형 변환 후에 적용되어 비선형성을 도입하고, 신경망이 다양한 현상을 학습할 수 있도록 돕는다.\n","##### 이 모델에서는 nn.ReLU를 선형 계층들 사이에 사용하지만, 모델을 만들 때는 비선형성을 가진 다른 활성화를 도입할 수도 있다."],"metadata":{"id":"0J4Qi_Lhl_wG"}},{"cell_type":"code","source":["print(hidden1)\n","hidden1 = nn.ReLU()(hidden1)\n","print(hidden1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6lP_V8rZl91r","executionInfo":{"status":"ok","timestamp":1702461290932,"user_tz":-540,"elapsed":3,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"c93e7fc7-d7ad-4e14-d515-f704d13afb70"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.2956,  0.3624,  0.1105, -0.3767,  0.0900, -0.1504, -0.0308, -0.2705,\n","          0.5809,  0.1460, -0.1946, -0.2400, -0.3889, -0.5061,  0.1346,  0.1025,\n","         -0.5879, -0.1551, -0.0907,  0.0187],\n","        [-0.3058,  0.2798,  0.1210, -0.3111,  0.2904,  0.0845, -0.0598, -0.6058,\n","          0.5334,  0.0027, -0.2465, -0.1340, -0.3277, -0.1591, -0.0327,  0.1774,\n","         -0.0294, -0.2157, -0.1473, -0.1175],\n","        [-0.2186,  0.4247,  0.2552, -0.2951,  0.0058,  0.2079, -0.1781, -0.1836,\n","          0.6106,  0.2582, -0.3131,  0.0051, -0.5280, -0.2735,  0.0240, -0.1589,\n","         -0.2537, -0.2357, -0.1165, -0.3570]], grad_fn=<AddmmBackward0>)\n","tensor([[0.0000, 0.3624, 0.1105, 0.0000, 0.0900, 0.0000, 0.0000, 0.0000, 0.5809,\n","         0.1460, 0.0000, 0.0000, 0.0000, 0.0000, 0.1346, 0.1025, 0.0000, 0.0000,\n","         0.0000, 0.0187],\n","        [0.0000, 0.2798, 0.1210, 0.0000, 0.2904, 0.0845, 0.0000, 0.0000, 0.5334,\n","         0.0027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1774, 0.0000, 0.0000,\n","         0.0000, 0.0000],\n","        [0.0000, 0.4247, 0.2552, 0.0000, 0.0058, 0.2079, 0.0000, 0.0000, 0.6106,\n","         0.2582, 0.0000, 0.0051, 0.0000, 0.0000, 0.0240, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"]}]},{"cell_type":"markdown","source":["### nn.Sequential\n","##### nn.Sequential : 순서를 갖는 모듈의 컨테이너이다. 데이터는 정의된 것과 같은 순서로 모든 모듈들을 통해 전달된다. 순차 컨테이너를 사용하여 아래의 seq_modules와 같은 신경망을 빠르게 만들 수 있다."],"metadata":{"id":"T1x6Qpvfmg68"}},{"cell_type":"code","source":["seq_modules = nn.Sequential(\n","    flatten,\n","    layer1,\n","    nn.ReLU(),\n","    nn.Linear(20,10)\n",")\n","input_image = torch.rand(3,28,28)\n","logits = seq_modules(input_image)\n","logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TW1vYrJembU5","executionInfo":{"status":"ok","timestamp":1702461620927,"user_tz":-540,"elapsed":9,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"13e53ab5-c8b8-4a3d-8a0c-8a40f4b009de"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0985, -0.1045,  0.0437,  0.2492,  0.0974, -0.2177,  0.0735, -0.0645,\n","          0.2221, -0.2123],\n","        [ 0.0283, -0.0846,  0.0422,  0.2375,  0.0527, -0.2745,  0.0976, -0.0827,\n","          0.2205, -0.2061],\n","        [ 0.0740, -0.0555, -0.0360,  0.2252,  0.0765, -0.2351,  0.0689, -0.0713,\n","          0.2760, -0.0414]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### nn.Softmax\n","##### 신경망의 마지막 선형 계층은 nn.Softmax 모듈에 전달될 logits를 반환한다.\n","##### logits는 모델의 각 분류에 대한 예측 확률을 나타내도록 [0, 1] 범위로 비례하여 조정된다. dim 매개변수는 값의 합이 1이 되는 차언을 나타낸다."],"metadata":{"id":"2EMzFeTtnunK"}},{"cell_type":"code","source":["softmax = nn.Softmax(dim=1)\n","pred_probab = softmax(logits)"],"metadata":{"id":"6TKolEFInqct","executionInfo":{"status":"ok","timestamp":1702461734721,"user_tz":-540,"elapsed":5,"user":{"displayName":"천준석","userId":"06369588489203998973"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["pred_probab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5pViF7HyoHmE","executionInfo":{"status":"ok","timestamp":1702461737178,"user_tz":-540,"elapsed":4,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"82ca3972-56e7-425a-adcb-4b10f19ed86d"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.1070, 0.0874, 0.1013, 0.1244, 0.1069, 0.0780, 0.1044, 0.0909, 0.1211,\n","         0.0784],\n","        [0.1013, 0.0905, 0.1027, 0.1249, 0.1038, 0.0748, 0.1086, 0.0906, 0.1227,\n","         0.0801],\n","        [0.1036, 0.0911, 0.0928, 0.1206, 0.1039, 0.0761, 0.1031, 0.0896, 0.1268,\n","         0.0923]], grad_fn=<SoftmaxBackward0>)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## 모델 매개변수\n","##### 신경망 내부의 많은 계층들은 매개변수화된다. 즉, 학습 중에 최적화되는 가중치와 편향과 연관지어진다.\n","##### nn.Module을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적되며, 모델의 parameters() 및 named_parameters() 메소드로 모든 매개변수에 접근할 수 있다."],"metadata":{"id":"wymQhx9yoKal"}},{"cell_type":"code","source":["print(f\"Model structure: {model}\\n\\n\")\n","\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5G64T9UoITc","executionInfo":{"status":"ok","timestamp":1702461845095,"user_tz":-540,"elapsed":6,"user":{"displayName":"천준석","userId":"06369588489203998973"}},"outputId":"6b72f1f2-488b-4185-a323-0fa0c98a27e8"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Model structure: NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","\n","\n","Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0231, -0.0206, -0.0115,  ..., -0.0223, -0.0351,  0.0082],\n","        [ 0.0272, -0.0162, -0.0340,  ...,  0.0334, -0.0115,  0.0159]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0319, 0.0301], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0375, -0.0053, -0.0314,  ..., -0.0408, -0.0323, -0.0326],\n","        [-0.0158,  0.0019, -0.0406,  ..., -0.0019,  0.0052, -0.0337]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0436, -0.0003], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0061, -0.0046,  0.0305,  ...,  0.0434, -0.0209,  0.0279],\n","        [ 0.0243, -0.0272, -0.0080,  ...,  0.0369, -0.0256,  0.0221]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0080, 0.0120], grad_fn=<SliceBackward0>) \n","\n"]}]}]}
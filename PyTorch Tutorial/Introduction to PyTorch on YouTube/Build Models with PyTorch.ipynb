{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543064ac-f68f-4eb4-9acd-48972da796c7",
   "metadata": {},
   "source": [
    "## Build Models with PyTorch\n",
    "PyTorch로 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5423e5-cf23-4e54-ba0b-7d5ddd1639bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model :\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer :\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params :\n",
      "Parameter containing:\n",
      "tensor([[-0.0031, -0.0222,  0.0984,  ..., -0.0924, -0.0979, -0.0472],\n",
      "        [-0.0567,  0.0364, -0.0484,  ..., -0.0287,  0.0276,  0.0179],\n",
      "        [ 0.0420, -0.0620,  0.0159,  ..., -0.0274, -0.0179,  0.0568],\n",
      "        ...,\n",
      "        [-0.0843,  0.0510,  0.0729,  ...,  0.0767, -0.0404, -0.0163],\n",
      "        [-0.0363, -0.0474,  0.0961,  ..., -0.0794, -0.0197,  0.0905],\n",
      "        [ 0.0785, -0.0861, -0.0437,  ..., -0.0634, -0.0240,  0.0320]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.2394e-02, -9.9673e-03,  4.2864e-02, -9.0315e-02,  4.0805e-02,\n",
      "         7.2054e-02,  1.7982e-02,  3.2671e-02,  5.1330e-02, -1.2510e-03,\n",
      "        -2.1270e-02, -1.3390e-02,  5.3449e-02, -7.7442e-02,  9.7127e-02,\n",
      "         8.4778e-02,  1.3372e-02,  2.1174e-02,  6.1005e-02, -4.0963e-02,\n",
      "         1.4913e-02, -1.4280e-02, -9.8490e-02,  1.9020e-02, -3.9004e-02,\n",
      "         7.6995e-02, -5.2704e-02,  6.1327e-02, -6.4293e-02, -4.4926e-02,\n",
      "         5.6948e-02,  8.3460e-02,  3.7376e-02,  1.4666e-02,  9.2089e-05,\n",
      "        -7.2379e-02,  4.4220e-02, -5.9859e-02, -9.4933e-02, -4.0261e-02,\n",
      "         3.1307e-02,  7.9129e-02,  4.1943e-02,  5.6438e-03, -5.0724e-02,\n",
      "        -6.0026e-02,  8.7298e-02,  9.0675e-02, -6.9558e-02, -2.5830e-02,\n",
      "         3.6064e-02, -8.4326e-02, -5.5851e-02,  7.4493e-02, -5.3721e-02,\n",
      "        -3.9074e-02, -8.2082e-02, -9.8783e-02,  4.0261e-02,  2.4153e-02,\n",
      "        -3.6594e-02, -1.0741e-02,  4.1208e-02, -5.4663e-02, -1.2282e-02,\n",
      "         9.7649e-02,  5.9652e-02, -4.7695e-02, -6.1555e-02, -3.9994e-02,\n",
      "         7.5081e-02,  1.2208e-02,  8.2516e-02, -7.3684e-02, -1.9097e-02,\n",
      "         3.5219e-02,  8.0352e-02, -8.1625e-02, -8.0300e-02,  8.2931e-02,\n",
      "        -3.8284e-03, -1.7963e-02, -2.2016e-02, -8.1097e-02, -1.6323e-02,\n",
      "         2.7714e-02,  8.1112e-02, -1.5479e-02, -4.1248e-02,  7.7920e-02,\n",
      "        -9.7721e-02,  1.1077e-02,  9.0919e-02, -2.2163e-02, -3.5528e-02,\n",
      "        -1.5330e-02, -2.3823e-02,  1.3399e-02,  9.0936e-02,  6.0887e-02,\n",
      "         3.1122e-02,  2.0151e-02, -9.4612e-02, -8.4372e-02,  5.2489e-02,\n",
      "        -1.2901e-02,  4.2922e-02,  2.0209e-02, -4.6502e-02, -8.5850e-02,\n",
      "        -4.0224e-02,  8.7371e-02,  4.4205e-02, -4.5400e-02,  5.3732e-02,\n",
      "        -2.4017e-02,  6.9008e-02, -7.6512e-02,  5.8606e-02, -1.6165e-02,\n",
      "         8.5232e-03, -7.9222e-02,  9.9789e-02,  5.7084e-03,  8.8773e-02,\n",
      "         3.4382e-02, -4.1038e-02,  5.3164e-03, -6.3198e-03, -1.8229e-02,\n",
      "         4.0544e-02,  2.8468e-02,  9.0162e-02,  5.8770e-02,  7.5840e-02,\n",
      "        -2.8201e-03,  6.5324e-02, -4.5850e-02,  8.2879e-02, -5.2646e-02,\n",
      "         6.7009e-02, -5.0912e-02,  8.8683e-02,  8.7377e-02,  8.0694e-02,\n",
      "        -2.0512e-02, -5.5285e-02,  8.5606e-02,  5.3034e-02, -1.5548e-02,\n",
      "         6.5784e-02,  5.5458e-02, -4.2827e-02,  1.1320e-02,  7.3963e-02,\n",
      "        -7.0273e-02, -5.5816e-02,  6.8681e-02,  1.1485e-02, -6.0181e-02,\n",
      "         4.6597e-02,  3.6617e-02, -4.0465e-02, -8.2663e-02,  1.5117e-02,\n",
      "         7.7388e-02,  2.2640e-02, -5.0754e-02, -7.7250e-02,  9.7821e-02,\n",
      "         1.9117e-02,  4.0925e-02,  4.0746e-02,  8.3254e-02,  3.9311e-02,\n",
      "        -7.7394e-02,  8.5099e-03,  4.5073e-02, -6.8095e-02,  9.6994e-02,\n",
      "         8.2870e-02, -9.9138e-02,  4.2255e-02,  5.2775e-02,  2.5013e-02,\n",
      "        -2.5998e-02,  6.5960e-02,  2.3717e-02,  2.7196e-02,  1.1961e-02,\n",
      "         5.1069e-02, -8.1453e-03,  3.8283e-02,  7.3614e-02,  7.6196e-02,\n",
      "        -2.7695e-02, -3.8164e-02,  9.6126e-02,  6.8841e-02, -4.3914e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0267,  0.0405,  0.0304,  ..., -0.0462,  0.0189, -0.0470],\n",
      "        [ 0.0389, -0.0144,  0.0650,  ..., -0.0398,  0.0414,  0.0457],\n",
      "        [-0.0571, -0.0260,  0.0038,  ..., -0.0201,  0.0641,  0.0619],\n",
      "        ...,\n",
      "        [-0.0183, -0.0293,  0.0525,  ...,  0.0328,  0.0480,  0.0456],\n",
      "        [-0.0357, -0.0449, -0.0042,  ..., -0.0210,  0.0692,  0.0134],\n",
      "        [ 0.0488,  0.0411,  0.0223,  ..., -0.0417,  0.0138,  0.0045]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0388,  0.0657,  0.0030, -0.0585,  0.0061, -0.0060, -0.0462,  0.0683,\n",
      "        -0.0100,  0.0572], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params :\n",
      "Parameter containing:\n",
      "tensor([[-0.0267,  0.0405,  0.0304,  ..., -0.0462,  0.0189, -0.0470],\n",
      "        [ 0.0389, -0.0144,  0.0650,  ..., -0.0398,  0.0414,  0.0457],\n",
      "        [-0.0571, -0.0260,  0.0038,  ..., -0.0201,  0.0641,  0.0619],\n",
      "        ...,\n",
      "        [-0.0183, -0.0293,  0.0525,  ...,  0.0328,  0.0480,  0.0456],\n",
      "        [-0.0357, -0.0449, -0.0042,  ..., -0.0210,  0.0692,  0.0134],\n",
      "        [ 0.0488,  0.0411,  0.0223,  ..., -0.0417,  0.0138,  0.0045]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0388,  0.0657,  0.0030, -0.0585,  0.0061, -0.0060, -0.0462,  0.0683,\n",
      "        -0.0100,  0.0572], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model :')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer :')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params :')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params :')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023ef4a-4944-4c3c-b0bb-9b29b29012d9",
   "metadata": {},
   "source": [
    "## Common Layer Types\n",
    "\n",
    "### Linear Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0e36fb-a240-4efc-b7f1-de5f32f6a275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :\n",
      "tensor([[0.3724, 0.1462, 0.6992]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters :\n",
      "Parameter containing:\n",
      "tensor([[ 0.3786, -0.4462,  0.1426],\n",
      "        [ 0.4345,  0.3068,  0.1365]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1608,  0.2749], requires_grad=True)\n",
      "\n",
      "\n",
      "Output :\n",
      "tensor([[0.0147, 0.5770]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input :')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters :')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput :')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4763af5-cf36-4a97-8ed5-9e96b3153343",
   "metadata": {},
   "source": [
    "### Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c08bb7-c2c0-4a25-81d9-74888c1f8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282e976-e0e6-4e1c-9a8e-3c38b3c368f8",
   "metadata": {},
   "source": [
    "### Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63d3679-27c0-467f-b112-3d3a28c1ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim = 1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e7ee5-347a-4db5-9b9b-444083173d97",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b247dde4-4918-4e28-aa6e-5a23d0208bb3",
   "metadata": {},
   "source": [
    "## Other Layers and Functions\n",
    "\n",
    "### Data Manipulation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8a80fd-78e4-437d-be77-b4141ca6a21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5947, 0.9470, 0.8487, 0.4166, 0.4971, 0.4190],\n",
      "         [0.0381, 0.7499, 0.8456, 0.5935, 0.0706, 0.1089],\n",
      "         [0.9596, 0.4914, 0.5083, 0.3930, 0.5609, 0.8478],\n",
      "         [0.2585, 0.4148, 0.5637, 0.9527, 0.2420, 0.0477],\n",
      "         [0.6764, 0.1093, 0.5605, 0.9452, 0.5564, 0.4071],\n",
      "         [0.3485, 0.5474, 0.9384, 0.9443, 0.6939, 0.1578]]])\n",
      "tensor([[[0.9596, 0.8478],\n",
      "         [0.9384, 0.9527]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d994e1c2-5e78-4c8b-814d-190d6113f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.7811,  7.7007,  7.5060, 20.2949],\n",
      "         [15.9749,  9.0530,  8.0327, 23.8550],\n",
      "         [21.2256, 13.4689, 18.6433, 22.8768],\n",
      "         [16.6556, 12.4958,  5.6967, 18.9211]]])\n",
      "tensor(14.3864)\n",
      "tensor([[[-0.5556, -0.5703, -0.6059,  1.7318],\n",
      "         [ 0.2753, -0.8161, -0.9770,  1.5178],\n",
      "         [ 0.6101, -1.5688, -0.1153,  1.0739],\n",
      "         [ 0.6387, -0.1881, -1.5397,  1.0891]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(4.4703e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712fd808-17ec-47c1-a9b4-ddac2ea3002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.2199, 0.1694, 0.0000],\n",
      "         [0.1455, 0.0000, 1.1674, 1.5979],\n",
      "         [0.0000, 0.2470, 0.0000, 0.0000],\n",
      "         [1.3426, 0.1901, 0.0000, 1.4240]]])\n",
      "tensor([[[0.7978, 0.2199, 0.1694, 1.3536],\n",
      "         [0.0000, 0.8682, 1.1674, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.3426, 0.1901, 0.0000, 1.4240]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4)\n",
    "\n",
    "dropout = torch.nn.Dropout(p = 0.4)\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e164a1-3643-4aa8-ba37-043997be3f12",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "### Loss Functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962495b4-ba3a-451b-b55b-18a589d75506",
   "metadata": {},
   "source": [
    "# Training with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4dea5-77c7-45fa-a5bc-72a884c8a507",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38242de2-2e31-4f24-96aa-d13d24d581c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 17:30:11.234329: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train = True, transform = transform, download = True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train = False, transform = transform, download = True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size = 4, shuffle = True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size = 4, shuffle = False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc6a7917-4054-4a19-abfa-cad5c211fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle Boot  Ankle Boot  T-shirt/top  Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel = False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim = 0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap = \"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel = True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837385df-c4a6-49b0-a412-acb7abd481a6",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bf6bf0-e9c1-4497-bf50-784e7dc8669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796e358-fd0b-439c-81b7-541562d0bce7",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a44a240-f765-4663-92a8-acecd579fdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9805, 0.2152, 0.3060, 0.6673, 0.6315, 0.6541, 0.6958, 0.5569, 0.7460,\n",
      "         0.5007],\n",
      "        [0.1383, 0.9279, 0.0051, 0.4823, 0.8220, 0.8309, 0.4798, 0.3044, 0.9343,\n",
      "         0.5116],\n",
      "        [0.0723, 0.5378, 0.4929, 0.8566, 0.1141, 0.4729, 0.1096, 0.6903, 0.6955,\n",
      "         0.4368],\n",
      "        [0.0673, 0.7053, 0.3444, 0.2057, 0.4285, 0.2522, 0.3122, 0.3418, 0.0130,\n",
      "         0.3866]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.244236707687378\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0e2751-a229-4a60-b956-a9d342e6c2a5",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4a9970-fcc7-483f-8ecf-443f07a1ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b081e31-faef-489f-bee3-81d59d66b14b",
   "metadata": {},
   "source": [
    "## The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d2ff84-7a8a-4acd-8f22-35b7bfb90e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b716d0-3d1f-47e0-9cd8-5e584207bf1a",
   "metadata": {},
   "source": [
    "## Per-Epoch Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577a5bce-4c33-4117-b202-9ed4f1094adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.6972096836417914\n",
      "  batch 2000 loss: 0.7931953736189753\n",
      "  batch 3000 loss: 0.6955412378422916\n",
      "  batch 4000 loss: 0.6412624048034195\n",
      "  batch 5000 loss: 0.5861652485015802\n",
      "  batch 6000 loss: 0.5472061970736831\n",
      "  batch 7000 loss: 0.5443089009048417\n",
      "  batch 8000 loss: 0.4925223593113478\n",
      "  batch 9000 loss: 0.4978586726265203\n",
      "  batch 10000 loss: 0.4741094887822401\n",
      "  batch 11000 loss: 0.4718062538233353\n",
      "  batch 12000 loss: 0.4702615833274322\n",
      "  batch 13000 loss: 0.45745908593869533\n",
      "  batch 14000 loss: 0.43212055423812124\n",
      "  batch 15000 loss: 0.41398172690928914\n",
      "LOSS train 0.41398172690928914 valid 0.44834238290786743\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.3988154220287688\n",
      "  batch 2000 loss: 0.4079406488982786\n",
      "  batch 3000 loss: 0.3951057787991595\n",
      "  batch 4000 loss: 0.39046277311537414\n",
      "  batch 5000 loss: 0.3998036955227726\n",
      "  batch 6000 loss: 0.37654656404227715\n",
      "  batch 7000 loss: 0.36584329812336364\n",
      "  batch 8000 loss: 0.371605843160316\n",
      "  batch 9000 loss: 0.3872855871036299\n",
      "  batch 10000 loss: 0.3562472201475757\n",
      "  batch 11000 loss: 0.3611665177245304\n",
      "  batch 12000 loss: 0.36938486905687024\n",
      "  batch 13000 loss: 0.3569942398946732\n",
      "  batch 14000 loss: 0.36853060379823727\n",
      "  batch 15000 loss: 0.3573182446336141\n",
      "LOSS train 0.3573182446336141 valid 0.36328208446502686\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.33642326445828075\n",
      "  batch 2000 loss: 0.33749365938061965\n",
      "  batch 3000 loss: 0.32134603136370427\n",
      "  batch 4000 loss: 0.3454225853971438\n",
      "  batch 5000 loss: 0.32413884320287617\n",
      "  batch 6000 loss: 0.34574546538588763\n",
      "  batch 7000 loss: 0.33109683167006004\n",
      "  batch 8000 loss: 0.308907481219816\n",
      "  batch 9000 loss: 0.31800909772224256\n",
      "  batch 10000 loss: 0.32521088324637915\n",
      "  batch 11000 loss: 0.3343941582976695\n",
      "  batch 12000 loss: 0.3227167964421824\n",
      "  batch 13000 loss: 0.3275709688054485\n",
      "  batch 14000 loss: 0.32330620566084783\n",
      "  batch 15000 loss: 0.32925057836133054\n",
      "LOSS train 0.32925057836133054 valid 0.32735949754714966\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.29675737312363343\n",
      "  batch 2000 loss: 0.31134857004576044\n",
      "  batch 3000 loss: 0.29905069470878154\n",
      "  batch 4000 loss: 0.3016445270733493\n",
      "  batch 5000 loss: 0.2989981382082515\n",
      "  batch 6000 loss: 0.31820769707912405\n",
      "  batch 7000 loss: 0.3103728457433463\n",
      "  batch 8000 loss: 0.28635956308404276\n",
      "  batch 9000 loss: 0.2817979060868529\n",
      "  batch 10000 loss: 0.30241468487150724\n",
      "  batch 11000 loss: 0.30723235331890464\n",
      "  batch 12000 loss: 0.28321035315103654\n",
      "  batch 13000 loss: 0.28736976324100394\n",
      "  batch 14000 loss: 0.30537824302133504\n",
      "  batch 15000 loss: 0.31352870100981456\n",
      "LOSS train 0.31352870100981456 valid 0.34303396940231323\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.3000440004371521\n",
      "  batch 2000 loss: 0.27747528722620884\n",
      "  batch 3000 loss: 0.2808602118907729\n",
      "  batch 4000 loss: 0.2761296851159859\n",
      "  batch 5000 loss: 0.2747150102624364\n",
      "  batch 6000 loss: 0.2970919228537241\n",
      "  batch 7000 loss: 0.254577199993324\n",
      "  batch 8000 loss: 0.2691266682636051\n",
      "  batch 9000 loss: 0.28200692886993056\n",
      "  batch 10000 loss: 0.2915626174729532\n",
      "  batch 11000 loss: 0.2675698224699736\n",
      "  batch 12000 loss: 0.27788800368529154\n",
      "  batch 13000 loss: 0.28358617443313416\n",
      "  batch 14000 loss: 0.28572446922335437\n",
      "  batch 15000 loss: 0.28418089030055854\n",
      "LOSS train 0.28418089030055854 valid 0.3179556429386139\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    {'Training' : avg_loss, 'Validation' : avg_vloss},\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022845d-8018-4874-a300-6336524f43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
